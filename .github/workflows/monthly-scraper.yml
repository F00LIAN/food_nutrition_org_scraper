name: Monthly Fast Food Nutrition Scraper

on:
  # Run on the 1st of every month at 2:00 AM UTC
  schedule:
    - cron: '0 2 1 * *'
  
  # Allow manual trigger from GitHub UI
  workflow_dispatch:
    inputs:
      max_restaurants:
        description: 'Maximum number of restaurants to scrape (leave empty for all)'
        required: false
        type: string
      max_items:
        description: 'Maximum items per restaurant (leave empty for all)'
        required: false
        type: string

jobs:
  scrape-nutrition-data:
    runs-on: ubuntu-latest
    timeout-minutes: 720  # 12 hours max runtime
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Create output directories
        run: |
          mkdir -p output
          mkdir -p output/checkpoints
      
      - name: Run scraper
        env:
          SCRAPER_LOG_LEVEL: INFO
          SCRAPER_OUTPUT_DIR: output
          SCRAPER_RATE_LIMIT: 1.0
        run: |
          if [ -n "${{ github.event.inputs.max_restaurants }}" ]; then
            export SCRAPER_MAX_RESTAURANTS=${{ github.event.inputs.max_restaurants }}
          fi
          if [ -n "${{ github.event.inputs.max_items }}" ]; then
            export SCRAPER_MAX_ITEMS_PER_RESTAURANT=${{ github.event.inputs.max_items }}
          fi
          python main.py
      
      - name: Generate summary report
        if: success()
        run: |
          echo "## Scraping Summary ðŸ“Š" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Date**: $(date)" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: âœ… Success" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ -f output/01_restaurants.json ]; then
            RESTAURANT_COUNT=$(python -c "import json; print(len(json.load(open('output/01_restaurants.json'))))")
            echo "- **Restaurants scraped**: $RESTAURANT_COUNT" >> $GITHUB_STEP_SUMMARY
          fi
          
          if [ -f output/02_menu_items.json ]; then
            MENU_ITEM_COUNT=$(python -c "import json; data=json.load(open('output/02_menu_items.json')); print(sum(len(v.get('items', [])) for v in data.values()))")
            echo "- **Menu items scraped**: $MENU_ITEM_COUNT" >> $GITHUB_STEP_SUMMARY
          fi
          
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Output Files ðŸ“" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
          ls -lh output/*.json 2>/dev/null || echo "No output files found"
          echo '```' >> $GITHUB_STEP_SUMMARY
      
      - name: Upload artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: nutrition-data-${{ github.run_number }}
          path: |
            output/*.json
            scraper.log
          retention-days: 90
      
      - name: Commit and push results (optional)
        if: success()
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          
          # Create a timestamped branch for this run
          TIMESTAMP=$(date +%Y%m%d_%H%M%S)
          BRANCH_NAME="scraper-results-$TIMESTAMP"
          
          git checkout -b $BRANCH_NAME
          git add output/*.json
          
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "ðŸ¤– Automated scrape results - $TIMESTAMP"
            git push origin $BRANCH_NAME
            echo "Results pushed to branch: $BRANCH_NAME" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "## Scraping Failed âŒ" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "The scraping job failed. Check the logs for details." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Triggered by**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "**Run ID**: ${{ github.run_id }}" >> $GITHUB_STEP_SUMMARY


